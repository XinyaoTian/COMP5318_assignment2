{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KmeansClustring.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOFgE7ix++sXE1TL93j3WfA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/XinyaoTian/COMP5318_assignment2/blob/master/KmeansClustring.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_ZBLi14k__C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Environment setup\n",
        "# Import assignment-wide packages\n",
        "import sklearn\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "np.random.seed(42)\n",
        "\n",
        "from random import uniform\n",
        "import math\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(action=\"ignore\", message=\"^internal gelsd\")\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-J55xVllHZv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "d1d9b861-735d-4a1f-c01f-d1a233f92735"
      },
      "source": [
        "# Load TripAdviosr dataset from its original source\n",
        "TA_data = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/00484/tripadvisor_review.csv\", sep=',', encoding=\"utf-8\")\n",
        "\n",
        "# It's obviously that 'User ID' is not meaningful when clustering\n",
        "# So we delete that column\n",
        "TA_data = TA_data.drop('User ID', 1)\n",
        "\n",
        "# Have a brief view\n",
        "TA_data.head()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Category 1</th>\n",
              "      <th>Category 2</th>\n",
              "      <th>Category 3</th>\n",
              "      <th>Category 4</th>\n",
              "      <th>Category 5</th>\n",
              "      <th>Category 6</th>\n",
              "      <th>Category 7</th>\n",
              "      <th>Category 8</th>\n",
              "      <th>Category 9</th>\n",
              "      <th>Category 10</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.93</td>\n",
              "      <td>1.8</td>\n",
              "      <td>2.29</td>\n",
              "      <td>0.62</td>\n",
              "      <td>0.80</td>\n",
              "      <td>2.42</td>\n",
              "      <td>3.19</td>\n",
              "      <td>2.79</td>\n",
              "      <td>1.82</td>\n",
              "      <td>2.42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.02</td>\n",
              "      <td>2.2</td>\n",
              "      <td>2.66</td>\n",
              "      <td>0.64</td>\n",
              "      <td>1.42</td>\n",
              "      <td>3.18</td>\n",
              "      <td>3.21</td>\n",
              "      <td>2.63</td>\n",
              "      <td>1.86</td>\n",
              "      <td>2.32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.22</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.54</td>\n",
              "      <td>0.53</td>\n",
              "      <td>0.24</td>\n",
              "      <td>1.54</td>\n",
              "      <td>3.18</td>\n",
              "      <td>2.80</td>\n",
              "      <td>1.31</td>\n",
              "      <td>2.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.45</td>\n",
              "      <td>1.8</td>\n",
              "      <td>0.29</td>\n",
              "      <td>0.57</td>\n",
              "      <td>0.46</td>\n",
              "      <td>1.52</td>\n",
              "      <td>3.18</td>\n",
              "      <td>2.96</td>\n",
              "      <td>1.57</td>\n",
              "      <td>2.86</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.51</td>\n",
              "      <td>1.2</td>\n",
              "      <td>1.18</td>\n",
              "      <td>0.57</td>\n",
              "      <td>1.54</td>\n",
              "      <td>2.02</td>\n",
              "      <td>3.18</td>\n",
              "      <td>2.78</td>\n",
              "      <td>1.18</td>\n",
              "      <td>2.54</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Category 1  Category 2  Category 3  ...  Category 8  Category 9  Category 10\n",
              "0        0.93         1.8        2.29  ...        2.79        1.82         2.42\n",
              "1        1.02         2.2        2.66  ...        2.63        1.86         2.32\n",
              "2        1.22         0.8        0.54  ...        2.80        1.31         2.50\n",
              "3        0.45         1.8        0.29  ...        2.96        1.57         2.86\n",
              "4        0.51         1.2        1.18  ...        2.78        1.18         2.54\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbvpGYR_lSTd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class KMeansClustering():\n",
        "\n",
        "  def __init__(self, Data, k_numbers=1, similarity='euclidean', convergence_threshold = 0.01):\n",
        "    self.Data = Data\n",
        "    self.k = k_numbers\n",
        "    self.similarity = similarity\n",
        "    self.centroids = None\n",
        "    self.DataDistributed = None\n",
        "    self.convergence_threshold = convergence_threshold\n",
        "  \n",
        "\n",
        "  # initate k numbers of centroids\n",
        "  def generate_initial_centroids(self):\n",
        "    # automatically generate initial centroids\n",
        "    i = 0\n",
        "    centroids = list()\n",
        "    while(i < self.k):\n",
        "      centroid = dict()\n",
        "      for column in self.Data.columns:\n",
        "        # randomly generate a value in the range of column\n",
        "        centroid[column] = float(\"{:.4f}\".format(uniform(self.Data[column].min(0), self.Data[column].max(0))))\n",
        "      centroids.append(centroid)\n",
        "      i += 1\n",
        "    # after generating centroids\n",
        "    self.centroids = pd.DataFrame(centroids)\n",
        "    return self.centroids\n",
        "\n",
        "\n",
        "  # assign points to a cluster located by a centroid\n",
        "  def assign_points(self):\n",
        "    # create a list to store the closest distance\n",
        "    distance_list = list()\n",
        "    cluster_index = list()\n",
        "    # iteration of rows(each point) in dataset\n",
        "    for index_point, point in self.Data.iterrows():\n",
        "      closest_distance = -1\n",
        "      distributed_centroid = -1\n",
        "      # for each point, calculate the distance from it to a centroid\n",
        "      for index_centroid, centroid in self.centroids.iterrows():\n",
        "        # ------ select distance type ------#\n",
        "        # select distance type\n",
        "        if self.similarity == \"euclidean\":\n",
        "          distance = self.euclidean_distance(point, centroid)\n",
        "        elif self.similarity == \"manhattan\":\n",
        "          distance = self.manhattan_distance(point, centroid)\n",
        "        elif self.similarity == \"minkowski\":\n",
        "          distance = self.minkowski_distance(point, centroid)\n",
        "        elif self.similarity == \"cosine\":\n",
        "          distance = self.cosine_distance(point, centroid)\n",
        "        else:\n",
        "          # throw out a warning\n",
        "          distance = -1\n",
        "        # ------ -------------------- ------#\n",
        "        # judge if new distance is closer than existing one\n",
        "        if closest_distance == -1 or distance < closest_distance:\n",
        "          # if it's true then update distance\n",
        "          closest_distance = distance\n",
        "          distributed_centroid = index_centroid\n",
        "      # append distance to storeage list\n",
        "      distance_list.append(closest_distance)\n",
        "      cluster_index.append(distributed_centroid)\n",
        "    # Add the cloest distance as a column to Dataframe\n",
        "    # Using copy() to avoid build a pointer between Data and DataDistributed\n",
        "    self.DataDistributed = self.Data.copy()\n",
        "    self.DataDistributed['Distance'] = distance_list\n",
        "    self.DataDistributed['Cluster_index'] = cluster_index\n",
        "    return self.DataDistributed\n",
        "\n",
        "\n",
        "  # generate empty centroid data structure\n",
        "  def generate_empty_centroids(self):\n",
        "    # automatically generate initial centroids\n",
        "    i = 0\n",
        "    centroids = list()\n",
        "    while(i < self.k):\n",
        "      centroid = dict()\n",
        "      for column in self.Data.columns:\n",
        "        # randomly generate a value in the range of column\n",
        "        centroid[column] = float(0.0)\n",
        "      centroids.append(centroid)\n",
        "      i += 1\n",
        "    return pd.DataFrame(centroids)\n",
        "  \n",
        "\n",
        "  # recalculate the centroid\n",
        "  def recalculate_centroid(self):\n",
        "    # recalculate centroids groupby previous clusters\n",
        "    # avoid Cluster_index become a new index\n",
        "    new_centroids = self.DataDistributed.groupby(['Cluster_index'], as_index=False).mean().round(4)\n",
        "    # drop middle-process columns\n",
        "    self.centroids = new_centroids.drop('Cluster_index', 1).drop('Distance', 1)\n",
        "    return self.centroids\n",
        "  \n",
        "\n",
        "  # main process of the whole training\n",
        "  def fit(self):\n",
        "    # randomly generate k centroids\n",
        "    self.generate_initial_centroids()\n",
        "    \n",
        "    convergence = False\n",
        "    # iterate until meet convergence condition\n",
        "    while convergence == False:\n",
        "      # assign points to these centroids\n",
        "      self.assign_points()\n",
        "      # take the previous centroids\n",
        "      previous_centroids = self.centroids.copy()\n",
        "      # recalculate the centroids\n",
        "      self.recalculate_centroid()\n",
        "      new_centroids = self.centroids.copy()\n",
        "\n",
        "      # judge if meeting convergence condition\n",
        "      for index, centroid in self.centroids.iterrows():\n",
        "        convergence = True\n",
        "        # ------ select distance type ------#\n",
        "        if self.similarity == \"euclidean\":\n",
        "          centroid_movement = self.euclidean_distance(previous_centroids.iloc[index], new_centroids.iloc[index])\n",
        "        elif self.similarity == \"manhattan\":\n",
        "          centroid_movement = self.manhattan_distance(previous_centroids.iloc[index], new_centroids.iloc[index])\n",
        "        elif self.similarity == \"minkowski\":\n",
        "          centroid_movement = self.minkowski_distance(previous_centroids.iloc[index], new_centroids.iloc[index])\n",
        "        elif self.similarity == \"cosine\":\n",
        "          centroid_movement = self.cosine_distance(previous_centroids.iloc[index], new_centroids.iloc[index])\n",
        "        # ------ -------------------- ------#\n",
        "        if centroid_movement >= self.convergence_threshold:\n",
        "          convergence = False\n",
        "      \n",
        "      \n",
        "  # euclidean distance\n",
        "  def euclidean_distance(self, pointA, pointB):\n",
        "    sum_of_square = 0.0\n",
        "    for column in self.Data.columns:\n",
        "      sum_of_square += (pointA[column] - pointB[column])**2\n",
        "    euclidean_distance = math.sqrt(sum_of_square)\n",
        "    return float(\"{:.4f}\".format(euclidean_distance))\n",
        "\n",
        "\n",
        "  # manhattan distance\n",
        "  def manhattan_distance(self, pointA, pointB):\n",
        "    sum_of_abs = 0.0\n",
        "    for column in self.Data.columns:\n",
        "      sum_of_abs += abs(pointA[column] - pointB[column])\n",
        "    manhattan_distance = sum_of_abs\n",
        "    return float(\"{:.4f}\".format(manhattan_distance))\n",
        "\n",
        "\n",
        "  # Minkowski distance\n",
        "  def minkowski_distance(self, pointA, pointB):\n",
        "    # get degree of features\n",
        "    degree = len(self.Data.columns)\n",
        "    sum_of_poly_item = 0.0\n",
        "    for column in self.Data.columns:\n",
        "      sum_of_poly_item += pow(float(\"{:.4f}\".format(pointA[column] - pointB[column])), degree)\n",
        "    minkowski_distance = pow(sum_of_poly_item, 1/degree)\n",
        "    return float(\"{:.4f}\".format(minkowski_distance))\n",
        "  \n",
        "\n",
        "  # Cosine distance\n",
        "  def cosine_distance(self, pointA, pointB):\n",
        "    sum_of_dot_product = 0.0\n",
        "    sum_of_square_pointA = 0.0\n",
        "    sum_of_square_pointB = 0.0\n",
        "    for column in self.Data.columns:\n",
        "      sum_of_dot_product += pointA[column] * pointB[column]\n",
        "      sum_of_square_pointA += pow(pointA[column], 2)\n",
        "      sum_of_square_pointB += pow(pointB[column], 2)\n",
        "    norm_of_pointA = math.sqrt(sum_of_square_pointA)\n",
        "    norm_of_pointB = math.sqrt(sum_of_square_pointB)\n",
        "    cosine_distance = sum_of_dot_product / (norm_of_pointA * norm_of_pointB)\n",
        "    return float(\"{:.4f}\".format(cosine_distance))\n",
        "\n",
        "\n",
        "  \n",
        "    \n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "kmeans = KMeansClustering(TA_data, k_numbers=3, similarity='manhattan')\n",
        "kmeans.fit()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5elUhal1mchF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bb2ee817-48b4-4ec3-adf1-974923ec2aa8"
      },
      "source": [
        "class KMeansClustering():\n",
        "\n",
        "  def __init__(self, Data, k_numbers=1, similarity='euclidean'):\n",
        "    self.Data = Data\n",
        "    self.k_numbers = k_numbers\n",
        "    self.similarity = similarity\n",
        "  \n",
        "  def generate_initial_centroids(self):\n",
        "    print(self.Data['Category 1'].max(0))\n",
        "    \n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "kmeans = KMeansClustering(TA_data)\n",
        "kmeans.generate_initial_centroids()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3.22\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIqRzAn8pm21",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}